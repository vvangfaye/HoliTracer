{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage.measure import label as ski_label, regionprops\n",
    "from tqdm import tqdm\n",
    "from tools.trans.mask_to_coco import build_polygon\n",
    "from tools.visual.visual_whole import visualize_coco_segmentation\n",
    "\n",
    "from holitracer.seg.engine import seg_predict_api\n",
    "from holitracer.vector.engine import vector_predict_api\n",
    "from holitracer.seg.models.unpernet import UPerNet\n",
    "from holitracer.vector.models.base import VLRAsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to vectorize one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, result_dir, seg_model, vector_model, downsample_factors):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    image_dir = os.path.dirname(image_path)\n",
    "    \n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "        \n",
    "    # segmentation\n",
    "    result_path, mask = seg_predict_api(\n",
    "                                    model=seg_model,\n",
    "                                    image_name=image_name,\n",
    "                                    result_dir=result_dir,\n",
    "                                    downsample_factors=downsample_factors,\n",
    "                                )\n",
    "    if mask is None:\n",
    "        return\n",
    "    \n",
    "    # trans2coco\n",
    "    polys = []\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    label_img = ski_label(mask > 0)\n",
    "    props = regionprops(label_img)\n",
    "    image_height, image_width = mask.shape\n",
    "    for prop in props:\n",
    "        prop_mask = np.zeros_like(mask)\n",
    "        prop_mask[prop.coords[:, 0], prop.coords[:, 1]] = 1\n",
    "        padded_binary_mask = np.pad(\n",
    "            prop_mask, pad_width=1, mode=\"constant\", constant_values=0\n",
    "        )\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(\n",
    "            padded_binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS\n",
    "        )\n",
    "        \n",
    "        poly = build_polygon(contours, hierarchy, 0, image_height, image_width)\n",
    "        if poly is None:\n",
    "            continue\n",
    "        polys.append(poly)\n",
    "        \n",
    "    # vectorization\n",
    "    refined_annotations = vector_predict_api(\n",
    "        model=vector_model,\n",
    "        image_path=image_path,\n",
    "        polys=polys,\n",
    "        d=25,\n",
    "    )\n",
    "    \n",
    "    return refined_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the segmentation and vectorization model (take whubuilding as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = UPerNet(\n",
    "    backbone='swin_l',\n",
    "    nclass=2,\n",
    ")\n",
    "seg_model_path = \"./data/models/whubuilding/seg/best_model.pth\"\n",
    "seg_model.load_state_dict(torch.load(seg_model_path)).cuda()\n",
    "seg_model.eval()\n",
    "\n",
    "vector_model = VLRAsModel(\n",
    "    num_points=32,\n",
    "    backbone_path=seg_model_path,\n",
    "    vlr_num=4\n",
    ")\n",
    "vector_model_path = \"./data/models/whubuilding/vector/best_model.pth\"\n",
    "vector_model.load_state_dict(torch.load(vector_model_path)).cuda()\n",
    "vector_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on one image and visualiza the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./data/datasets/WHU_building_dataset/test/img/150000_220000.jpg\"\n",
    "coco_result = process_image(image_path, \"./data/results\", seg_model, vector_model, [1, 3, 6])\n",
    "json.dump(coco_result, open(\"./data/results/150000_220000.json\", \"w\"))\n",
    "# visualize\n",
    "visualize_coco_segmentation(\n",
    "    image_path=image_path,\n",
    "    json_path=\"./data/results/150000_220000.json\",\n",
    "    save_dir=\"./data/results/\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
